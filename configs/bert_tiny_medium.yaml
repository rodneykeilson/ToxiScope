# ToxiScope: BERT-tiny on Medium Dataset
# 50K train, 10K val for better performance

model:
  name: "prajjwal1/bert-tiny"
  num_labels: 7
  max_length: 128

training:
  output_dir: "outputs/models/bert_tiny_medium"
  batch_size: 32
  gradient_accumulation_steps: 1
  learning_rate: 5e-4
  weight_decay: 0.01
  num_epochs: 3
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  
  optimizer: "adamw"
  adam_epsilon: 1e-8
  scheduler: "linear"
  
  loss_function: "focal"
  focal_gamma: 2.0
  focal_alpha: 0.25
  
  early_stopping_patience: 3
  early_stopping_threshold: 0.001
  
  eval_steps: 500
  save_steps: 500
  logging_steps: 100
  
  fp16: false
  dataloader_num_workers: 0

data:
  train_path: "data/training/medium/train.csv"
  val_path: "data/training/medium/val.csv"
  test_path: "data/training/medium/test.csv"
  text_column: "body_clean"
  label_columns:
    - "toxic"
    - "severe_toxic"
    - "obscene"
    - "threat"
    - "insult"
    - "identity_hate"
    - "racism"

output:
  dir: "outputs/models/bert_tiny_medium"
  save_total_limit: 2

wandb:
  project: "toxiscope"
  name: "bert-tiny-medium"
  tags: ["bert-tiny", "medium", "cpu"]
