# ToxiScope: BERT-base for Comparison
# Heavy baseline for comparison table

model:
  name: "bert-base-uncased"
  num_labels: 7
  max_length: 128

training:
  batch_size: 8
  gradient_accumulation_steps: 4
  learning_rate: 2e-5
  weight_decay: 0.01
  num_epochs: 1
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  
  optimizer: "adamw"
  adam_epsilon: 1e-8
  scheduler: "linear"
  
  loss_function: "focal"
  focal_gamma: 2.0
  focal_alpha: 0.25
  
  early_stopping_patience: 2
  early_stopping_threshold: 0.001
  
  eval_steps: 500
  save_steps: 500
  logging_steps: 100
  
  fp16: false
  dataloader_num_workers: 0

data:
  train_path: "data/training/medium/train.csv"
  val_path: "data/training/medium/val.csv"
  test_path: "data/training/medium/test.csv"
  text_column: "body_clean"
  label_columns:
    - "toxic"
    - "severe_toxic"
    - "obscene"
    - "threat"
    - "insult"
    - "identity_hate"
    - "racism"

output:
  dir: "outputs/models/bert_base_baseline"
  save_total_limit: 2

wandb:
  project: "toxiscope"
  name: "bert-base-baseline"
  tags: ["bert-base", "baseline", "comparison"]
